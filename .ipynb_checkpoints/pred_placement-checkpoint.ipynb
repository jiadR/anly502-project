{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"model_building\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 's3://502pubg/clean/aggeragate2.parquet'\n",
    "data = spark.read.parquet(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- game_size: integer (nullable = true)\n",
      " |-- match_mode: string (nullable = true)\n",
      " |-- party_size: integer (nullable = true)\n",
      " |-- player_assists: integer (nullable = true)\n",
      " |-- player_dbno: integer (nullable = true)\n",
      " |-- player_dist_ride: integer (nullable = true)\n",
      " |-- player_dist_walk: integer (nullable = true)\n",
      " |-- player_dmg: integer (nullable = true)\n",
      " |-- player_kills: integer (nullable = true)\n",
      " |-- player_survive_time: integer (nullable = true)\n",
      " |-- team_placement: integer (nullable = true)\n",
      " |-- matchmode_index: double (nullable = true)\n",
      " |-- label: double (nullable = true)\n",
      " |-- gamesize_index: double (nullable = true)\n",
      " |-- partysize_index: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- stdfeatures: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder, \\\n",
    "    StringIndexer, IndexToString, VectorAssembler, StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare pipiline\n",
    "vectorAssembler_features = VectorAssembler(\n",
    "    inputCols=['player_assists','player_dbno','player_dist_ride',\n",
    "               'player_dist_walk','player_dmg','player_kills','matchmode_index',\n",
    "               \"gamesize_index\",\"partysize_index\"], \n",
    "    outputCol=\"features\",handleInvalid=\"skip\")\n",
    "\n",
    "# scale features\n",
    "scal = StandardScaler(inputCol='features',outputCol='stdfeatures',withStd=True, withMean=False)\n",
    "\n",
    "# fit model\n",
    "model_fit = LinearRegression(featuresCol = 'stdfeatures', \n",
    "                      labelCol='team_placement', maxIter=10, regParam=0.3, elasticNetParam=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.select(['player_assists','player_dbno','player_dist_ride',\n",
    "               'player_dist_walk','player_dmg','player_kills','matchmode_index',\n",
    "               \"gamesize_index\",\"partysize_index\", \"team_placement\"])\n",
    "train_df, test_df = df.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start pipeline\n",
    "pipeline = Pipeline(stages=[vectorAssembler_features, \n",
    "                            scal,\n",
    "                            model_fit])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_std = pipeline.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [-0.5273252206732283,3.2100739399024434,-5.328388928736673,-0.9313110566766926,-3.5683834637655365,-3.1494299580433993,0.0,-0.5582667229764633,12.847622943525609]\n",
      "Intercept: 19.08657108957678\n"
     ]
    }
   ],
   "source": [
    "linear_std_model = linear_std.stages[-1]\n",
    "print(\"Coefficients: \" + str(linear_std_model.coefficients))\n",
    "print(\"Intercept: \" + str(linear_std_model.intercept))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 13.427718\n",
      "r2: 0.566009\n"
     ]
    }
   ],
   "source": [
    "linear_std_trainingSummary = linear_std_model.summary\n",
    "print(\"RMSE: %f\" % linear_std_trainingSummary.rootMeanSquaredError)\n",
    "print(\"r2: %f\" % linear_std_trainingSummary.r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing summary (standardized features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R Squared (R2) on test data = 0.565071\n"
     ]
    }
   ],
   "source": [
    "linear_std_predictions = linear_std.transform(test_df)\n",
    "\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "linear_std_evaluator = RegressionEvaluator(predictionCol=\"prediction\",\n",
    "                 labelCol=\"team_placement\",metricName=\"r2\")\n",
    "\n",
    "print(\"R Squared (R2) on test data = %g\" % linear_std_evaluator.evaluate(linear_std_predictions))\n",
    "\n",
    "test_df = vectorAssembler_features.transform(test_df)\n",
    "test_df = scal.fit(test_df).transform(test_df)\n",
    "linear_std_test_result = linear_std_model.evaluate(test_df)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % linear_std_test_result.rootMeanSquaredError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First fit standardized features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare pipiline\n",
    "vectorAssembler_features = VectorAssembler(\n",
    "    inputCols=['player_assists','player_dbno','player_dist_ride',\n",
    "               'player_dist_walk','player_dmg','player_kills','matchmode_index',\n",
    "               \"gamesize_index\",\"partysize_index\"], \n",
    "    outputCol=\"features\",handleInvalid=\"skip\")\n",
    "\n",
    "# scale features\n",
    "scal = StandardScaler(inputCol='features',outputCol='stdfeatures',withStd=True, withMean=False)\n",
    "\n",
    "# fit model\n",
    "model_fit = DecisionTreeRegressor(labelCol=\"team_placement\", featuresCol=\"stdfeatures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.select(['player_assists','player_dbno','player_dist_ride',\n",
    "               'player_dist_walk','player_dmg','player_kills','matchmode_index',\n",
    "               \"gamesize_index\",\"partysize_index\", \"team_placement\"])\n",
    "train_df, test_df = df.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start pipeline\n",
    "pipeline = Pipeline(stages=[vectorAssembler_features, \n",
    "                            scal,\n",
    "                            model_fit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_std = pipeline.fit(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 7.07401\n"
     ]
    }
   ],
   "source": [
    "tree_std_predictions = tree_std.transform(test_df)\n",
    "tree_std_evaluator = RegressionEvaluator(\n",
    "    labelCol=\"team_placement\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "\n",
    "rmse = tree_std_evaluator.evaluate(tree_std_predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature importances (standardized features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(9, {2: 0.0113, 3: 0.5218, 4: 0.0022, 7: 0.002, 8: 0.4627})"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_std.stages[-1].featureImportances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(player_assists=0, player_dbno=0, player_dist_ride=3737, player_dist_walk=1443, player_dmg=0, player_kills=0, matchmode_index=0.0, gamesize_index=1.0, partysize_index=0.0, team_placement=3)]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Player distance walk and party size play important roles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
